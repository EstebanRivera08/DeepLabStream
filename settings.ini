[Streaming]
RESOLUTION = 848, 480
FRAMERATE = 30
OUTPUT_DIRECTORY = /Output
#if you have connected multiple cameras (USB), you will need to select the number OpenCV has given them.
#Default is "0", which takes the first available camera.
CAMERA_SOURCE = 0
#you can use camera, ipwebcam or video to select your input source
STREAMING_SOURCE = camera

[Pose Estimation]
#possible origins are: DLC, DLC-LIVE, MADLC, DEEPPOSEKIT
MODEL_ORIGIN = ORIGIN
MODEL_PATH = PATH_TO_MODEL
MODEL_NAME = MODEL_NAME
; only used in DLC-LIVE and DeepPoseKit for now; if left empty or to short,  auto-naming will be enabled in style bp1, bp2 ...
ALL_BODYPARTS = bp1, bp2, bp3, bp4

[Experiment]
#Available parameters are "CUSTOM" and "BASE"
EXP_ORIGIN = CUSTOM
#Name of the experiment config in /experiments/configs or name of the custom experiment in /experiments/custom/experiments.py
EXP_NAME = ExampleExperiment
#if you want the experiment to be recorded as a raw video set this to "True".
RECORD_EXP = True

[Classification]
PATH_TO_CLASSIFIER = CLASSIFIER_PATH
#time window used for feature extraction (currently only works with 15)
TIME_WINDOW = 15
#number of parallel classifiers to run, this is dependent on your performance time. You need at least 1 more classifier then your average classification time.
POOL_SIZE = 4
#threshold to accept a classification probability as positive detection (SIMBA + )
THRESHOLD = 0.5
# class/category of identified behavior to use as trigger (only used for B-SOID)
TRIGGER = 5
#feature extraction currently works with millimeter not px, so be sure to enter the factor (as in simba).
PIXPERMM = 6.132

[Video]
#Full path to video that you want to use as input. Needs "STREAMING_SOURCE" set to "video"!
VIDEO_SOURCE = PATH_TO_PRERECORDED_VIDEO

[IPWEBCAM]
#Standard Port is 5555 if you followed the SmoothStream setup
PORT = 5555
